---
layout: post
title: "형식 모형: 통계적 프레임워크"
author: 김태원
categories: MachineLearning
tags: [MachineLearning]
---

> *Shai Shalev-Shwartz와 Shai Ben-David의 [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf){:target="_blank"}을 읽으며 기록한 내용입니다.*
>
> <h3>관련 글</h3>
>
> [1.1 학습이란 무엇인가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml0){:target="_blank"} 
>
> [1.2 기계 학습은 언제 필요한가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml02){:target="_blank"}

누가 조만간 마트에서 양파를 난생 처음 사본다고 하자.
경도나 색으로 양파의 질을 판단할 수 있지만, 그는 어떤 색과 경도가 맛있는 양파를 결정하는지 모른다. 
그래서 학습하고자 한다.
형식 모형(formal model), 즉 **통계적 학습 프레임워크**(statistical learning framework)를 기술할 필요가 있겠다. 

우선 학습자에게 어떤 **입력**을 제공할지 확인하겠다.
학습자에게는 보통 **도메인 집합**(domain set), **라벨 집합**(lael set), **훈련 데이터**(training data)가 입력으로 필요하다.

도메인 집합이란 정의역과 비슷한 뜻을 지닌 집합 $X$로, 이 경우에는 모든 양파의 집합과 같은 것이겠다.
도메인 집합은 특징(feature)들의 벡터를 원소로 지닌다.
그리고 도메인상의 이들 벡터--점을 **인스턴스**(instances)라고 부르며 $X$를 인스턴스 공간(instance space)이라고 부른다. 

또한 이 경우 라벨 집합을 두 개의 원소를 지닌 집합으로 제한할 수 있다. 
맛있다는 뜻의 $1$과 $0$을 원소로 삼을 수 있겠다.
이에 $Y$를 모든 라벨 집합의 집합이라고 하자. 
그리고 $S=((x_1,y_1)\ldots(x_m,y_m))$를 $X\times Y$상의 모든 순서쌍에 대한 유한 수열이라고 하자. 
다시 말해 $S$는 라벨이 부여된 인스턴스들의 수열이다. 
이들 인스턴스를 훈련 예제(training example)이라고 부른다.

도메인, 라벨, 훈련 집합으로 구성된 입력에 대해 학습자는 **예측 규칙**(prediction rule)을 출력해야 한다.
예측 규칙 $h:X\rightarrow Y$는 **가설**(hypothesis)이나 **분류기**(classifier)라고 부르기도 한다. 
이 경우, 학습자가 새로운 양파를 보면 그 질을 예측하여 라벨을 부여하는 규칙이 바로 함수 $h:X\rightarrow Y$다. 
학습 알고리즘 $A$가 훈련 예제들의 수열 $S$에 대해 반환하는 예측 규칙을 $A(S)$라고 표기하기도 한다.

그런데 훈련 데이터는 어떻게 생성하는가?
우선 인스턴스가 확률 분포 $D$에 의해 생성된다고 하자.
이때 핵심은 학습자가 $D$를 안다고 가정하지 않는다는 사실이다.
이어서 **올바른** 라벨 부여 함수 $f:X\rightarrow Y$가 존재하여 $y_i=f(x_i)$를 만족한다고 가정한다. 
마찬가지로 학습자에게는 $f:X\rightarrow Y$가 주어지지 않는다.
$f:X\rightarrow Y$는 학습자가 알아내고자 하는 것이다. 

이에 앞서 언급한 분류기 혹은 예측 규칙 $h:X\rightarrow Y$의 오류는 $x\in X$와 분포 $D$에 대해 $h(x)\neq f(x)$인 확률이다. 
주어진 도메인에 대한 부분집합 $A\subset X$와 확률 분포 $D$에 수 $D(A)$를 배정할 수도 있다.
$D(A)$는 $x\in A$라는 점을 관찰할 수 있을 정도를 나타낸다.  
대부분 $A$는 하나의 사건을 지시하며 이 사건은 함수 $\pi:X\rightarrow\lbrace 0, 1 \rbrace$로 아래처럼 나타낸다.

$$
A=\lbrace x\in X:\pi(x)=1\rbrace.
$$

이에 분류기 혹은 예측 규칙 $h:X\rightarrow Y$의 오류를 다음처럼 정의한다.

$$
\begin{align*}
L_{(D,f)}(h) &:= D(A) \\
		&:= \underset{x\sim D}{\mathbb{P}}[h(x)\neq f(x)] \\
		&:= D(\lbrace x:h(x)\neq f(x)\rbrace).
\end{align*}
$$

즉 예측 규칙 $h:X\rightarrow Y$의 오류는 $h(x)\neq f(x)$인 $x$를 선택하는 확률이다. 
또한 여기서 $(D,f)$라는 첨자 표기는 오류가 확률 분포 $D$와 올바른 라벨 함수 $f$로 측정되었다는 것을 나타낸다. 
$L_{(D,f)}$를 **일반화 오류**나 **리스크**라고 부르기도 한다.

핵심은 학습자에게는 양파의 확률 분포와 올바른 판단 기준--라벨 함수가 주어지지 않는다는 사실이다.
학습자는 우선 훈련 데이터, 가령 샘플 양파를 관찰해서 가설을 세워야 한다.
그리고 가설에 존재하는 오류는 올바른 양파 선택 규칙의 결과와 가설의 결과가 다른 양파를 선택하는 확률로 정의된다.
