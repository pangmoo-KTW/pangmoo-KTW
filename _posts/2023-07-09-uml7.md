---
layout: post
title: "실현가능성과 i.i.d 가정"
author: 김태원
categories: MachineLearning
tags: [MachineLearning]
---

> *Shai Shalev-Shwartz와 Shai Ben-David의 [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf){:target="_blank"}을 읽으며 기록한 내용입니다.*
>
> <h3>관련 글</h3>
>
> [1. 학습이란 무엇인가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml0){:target="_blank"} 
>
> [2. 기계 학습은 언제 필요한가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml02){:target="_blank"}
>
> [3. 형식 모형: 통계적 프레임워크](https://pangmoo-ktw.github.io/pangmoo-KTW/uml21){:target="_blank"}
>
> [4. 경험적 리스크 최소화](https://pangmoo-ktw.github.io/pangmoo-KTW/uml22){:target="_blank"}
>
> [5. 귀납 편향에 따른 경험적 리스크 최소화](https://pangmoo-ktw.github.io/pangmoo-KTW/uml23){:target="_blank"}


[유한 가설류](https://pangmoo-ktw.github.io/pangmoo-KTW/uml6) $\mathcal{H}$에 대한 $\textrm{ERM}_{\mathcal{H}}$ 학습규칙을 다루기 위해
어떤 $f:X\rightarrow Y$에 대해 레이블된 훈련 예제 $S$가 있고 $h_S$는 $\textrm{ERM}_{\mathcal{H}}$을 $S$에 적용한 결과라고 하자.

$$
h_S\in\underset{h\in\mathcal{H}}{\textrm{argmin }}L_S(h).
$$

이에 몇 가지 가정을 도입하겠다.

---
**정의 2.1 (실현가능성 가정)**

$h'\in\mathcal{H}$가 존재하여 $L_{(D,f)}(h')=0$이라고 하자. 
(이 가정은 $S$의 인스턴스가 $D$로 표본화되고 $f$로 라벨을 부여받아  임의의 표본에 대해 $1$의 확률을 지닌다면 $L_S(h')=0$일 것을 암시한다.)

---

통계적 기계 학습에서 통용되는 또 다른 가정은 표본 $S$가 $D$상의 여러 표본화 지점에서 서로 독립적으로 만들어진다는 것이다. 
이를 **i.i.d. 가정**(independently and identically distributed)이라고 부른다.

---
**i.i.d. 가정** 

훈련 예제는 분포 $D$에 따라 **고유하고 독립적으로 분포된다**고 하자.
즉, 모든 $x_i\in S$는 $D$에 따라 새롭게 표본화된 다음 라벨 함수 $f$에 의해 라벨을 부여받는다.
이 가정을 $S\sim D^m$이라고 표기한다.
여기서 $m$은 $S$의 크기다.
또한 $D^m$은 여타 튜플 요소에 독립적으로 튜플상의 각 요소를 선택하도록 $D$를 적용하여 유도한 $m$-튜플에 대한 확률이다.

---

$L_{(D,f)}(h_S)$가 훈련 집합 $S$에 의존하고 $S$가 무작위적인 절차로 선택되었기에 예측기 $h_S$의 선택과 리스크 $L_{(D,f)}(h_S)$에는 무작위성이 존재한다.
이를 **무작위 변수**라고 부른다.

그런데 표본화된 훈련 데이터가 $D$를 전혀 대변하지 않을 수도 있다.

이처럼 비대변적 표본을 취할 확률을 $\sigma$라고 표기하며 $(1-\sigma)$를 **신뢰 모수**(confidence parameter)라고 부르겠다.
또한 완벽한 라벨 예측을 보장하는 것이 불가능하기에 예측의 질에 대한 또 다른 모수인 **정확도 모수**(accuracy parameter) $\varepsilon$을 도입한다.

학습자의 실패는 $L_{(D,f)}(h_S)>\varepsilon$이다.
$L_{(D,f)}(h_S)\leq\varepsilon$이라면 알고리즘의 출력은 근사적으로 정확한 예측기다.
따라서 문제는 인스턴스의 $m$-튜플을 표본화하는 확률에 대한 상계다.
이 상계는 학습자의 실패를 유도할 것이다.

$S|_x=(x_1,\ldots,x_m)$가 훈련 집합의 인스턴스라고 하자.
이에 상계를 부여하고 한다.

$$
D^m(\lbrace S|_x:L_{(D,f)}(h_S)>\varepsilon)\rbrace).
$$

그리고 $\mathcal{H}_B$를 나쁜 가설의 집합이라고 하자.

$$
\mathcal{H}=\lbrace h\in\mathcal{H}:L_{(D,f)}(h)>\varepsilon\rbrace.
$$

이에 오도적인 표본의 집합을 $M$이라고 하자.

$$
M=\lbrace S\vert_x:\exists h\in\mathcal{H}_B,L_S(h)=0\rbrace.
$$

즉 모든 $S\vert_x\in M$에대해 좋은 가설로 보이는 나쁜 가설 $h\in\mathcal{H}_B$가 존재한다.

그리고 **실현가능성 공리**에 의해 어떤 $h\in\mathcal{H}_B$에 대해 $L_S(h_S)=0$인 경우에만 $L_{(D,f)}(h_S)>\varepsilon$이다.

다시 말해 표본이 오도적인 표본의 집합 $M$의 원소인 경우만 $L_(D,f)(h_S)>0$일 수 있다.

$$
\lbrace S|_x:L_{(D,f)}(h_S)>\varepsilon\rbrace\subseteq M.
$$

이에 $M$을 아래처럼 다시 나타낼 수 있다.

$$
M = \bigcup_{h\in\mathcal{H}_B}\lbrace S|_x:L_S(h)=0\rbrace.
$$
