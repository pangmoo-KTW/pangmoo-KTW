---
layout: post
title: "경험적인 리스크 최소화하기"
author: 김태원
categories: MachineLearning
tags: [MachineLearning]
---

> *Shai Shalev-Shwartz와 Shai Ben-David의 [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf){:target="_blank"}을 읽으며 기록한 내용입니다.*
>
> <h3>관련 글</h3>
>
> [1. 학습이란 무엇인가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml0){:target="_blank"} 
>
> [2. 기계 학습은 언제 필요한가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml02){:target="_blank"}
>
> [3. 형식 모형: 통계적 프레임워크](https://pangmoo-ktw.github.io/pangmoo-KTW/uml21){:target="_blank"}

[형식 모형: 통계적 프레임워크](https://pangmoo-ktw.github.io/pangmoo-KTW/uml21)에서 말했듯이 학습 알고리즘은 입력으로 유한수열 $S$를 취한다.
이때 $S$는 미지의 확률 분포 $D$로 표본화되고 어떤 목적 함수 $f$로 라벨을 부여받은 것이다. 
그리고 학습 알고리즘은 예측기 $h_S:X\rightarrow Y$를 출력해야 한다.
학습 알고리즘의 목표는 미지의 $D$와 $f$에 대해 오류를 최소화하는 $h_S$를 찾는 것이다.

문제는 학습자가 $D$나 $f$도 모르기에 올바른 오류도 알 수 없다는 사실이다. 
이에 학습자가 계산할 수 있는 오류는 **훈련 오류**(training error)다.
훈련 오류란 $[m]=\lbrace1,\ldots,m\rbrace$에 대해 아래와 같다.

$$
L_S(h) := \frac{|\lbrace i\in[m] : h(x_i)\neq y_i\rbrace|}{m}.
$$

훈련 오류를 **경험적인 오류** 혹은 **경험적인 리스크**(emperical risk)라고 부르기도 한다. 
또한 $L_S(h)$를 최소화하는 예측기 $h$에 따른 학습 패러다임은 **경험적 리스크 최소화**(Emperical Risk Minimization), 짧게 ERM이라고 한다.

ERM은 자연스러워 보이지만 처참하게 실패할 수도 있다.
아래 같은 예측기를 보자.

$$
h_S(x)=\begin{cases}y_i\quad\Leftarrow\exists i\in[m]:x_i=x \\ 0\quad\Leftarrow\forall i\notin[m]:x_i\neq x\end{cases}
$$

표본과 무관하게, $L_S(h_S)=0$이다. 
따라서 ERM이 채택할 법한 예측기다.
하지만 어떤 예측기는 훈련 예제에서 탁월한 성능을 보이지만 실제 세상에서는 전혀 그렇지 않다. 
이 현상을 **과적합**(overfitting)이라고 부른다. 
과적합은 말 그대로 가설이 훈련 데이터에 너무 과하게 적합할 때 일어나는 현상이다. 
