---
layout: post
title: "유한 가설류 (작성 중)"
author: 김태원
categories: MachineLearning
tags: [MachineLearning]
---

> *Shai Shalev-Shwartz와 Shai Ben-David의 [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf){:target="_blank"}을 읽으며 기록한 내용입니다.*
>
> <h3>관련 글</h3>
>
> [1. 학습이란 무엇인가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml0){:target="_blank"} 
>
> [2. 기계 학습은 언제 필요한가?](https://pangmoo-ktw.github.io/pangmoo-KTW/uml02){:target="_blank"}
>
> [3. 형식 모형: 통계적 프레임워크](https://pangmoo-ktw.github.io/pangmoo-KTW/uml21){:target="_blank"}
>
> [4. 경험적 리스크 최소화](https://pangmoo-ktw.github.io/pangmoo-KTW/uml22){:target="_blank"}
>
> [5. 귀납 편향에 따른 경험적 리스크 최소화](https://pangmoo-ktw.github.io/pangmoo-KTW/uml23){:target="_blank"}

[귀납 편향에 따른 경험적 리스크 최소화](https://pangmoo-ktw.github.io/pangmoo-KTW/uml23)에서 말했듯이 가설류(hypothesis class)에 대한 제한으로 과적합을 방지할  수 있다.
클래스(class, 류)에 가할 수 있는 가장 간단한 제한은 바로 클래스의 크기에 **상계**를 두는 것이다.
다시 말해, 예측기 $h\in\mathcal{H}$의 수를 고정하는 것이다. 

이처럼 유한 가설류로 예측기를 제한하는 것은 적당한 해결책으로 보인다. 
가령 $\mathcal{H}$가 C++ 프로그램상 최대 $10^9$ 비트의 코드로 구현할 수 있는 모든 예측기의 집합이라고 하자. 
무한한 가설류에 대해 실수 표현을 부동소수점수 표현으로 이산화(discretize)하면, 가설류가 유한할 수 있을 것이다.

이제 유한류 $\mathcal{H}$에 대한 $\textrm{ERM}_{\mathcal{H}}$ 학습 규칙의 성능을 분석하겠다.

어떤 $f:X\rightarrow Y$에 대해 레이블된 훈련 예제 $S$가 있고 $h_S$는 $\textrm{ERM}_{\mathcal{H}}$을 $S$에 적용한 결과라고 하자.

$$
h_S\in\underset{h\in\mathcal{H}}{\textrm{argmin }}L_S(h).
$$

이에 아래 같은 단순화 가정을 취하겠다.

---
**정의 2.1 (실현가능성 가정)**

$h'\in\mathcal{H}$가 존재하여 $L_{(D,f)}(h')=0$이라고 하자. 
이 가정은 $S$의 인스턴스가 $D$로 표본화되고 $f$로 라벨을 부여받아  임의의 표본에 대해 $1$의 확률을 지닌다면 $L_S(h')=0$일 것을 암시한다.

---

실현가능성 가정은 모든 $\mathrm{ERM}$ 가설에 대해 $L_S(h_S)=0$인 가설의 존재를 암시한다.
물론 이런 경험적 리스크보다 중요한 것은 $$L_{(D,f)}(h_S)$, 즉 $h_S$의 **진짜 리스크**라는 문제다.

그리고 표본 $S$에만 접근할 수 있는 알고리즘과 표본 $D$에 대한 오류 보장은 분명 $D$와 $S$의 관계에 의존하는 문제다. 
이에 통계적 기계 학습의 일반적인 가정은 표본 $S$가 $D$상의 여러 표본화 지점에서 서로 독립적으로 생성되었다는 것이다. 
이를 **i.i.d. 가정**(independently and identically distributed)이라고 부른다.

---
**i.i.d. 가정** 

훈련 예제는 분포 $D$에 따라 **고유하고 독립적으로 분포된다**고 가정한다.
즉, 모든 $x_i\in S$는 $D$에 따라 새롭게 표본화된 다음 라벨 함수 $f$에 의해 라벨을 부여받는다.
이 가정을 $S\sim D^m$이라고 표기한다.
여기서 $m$은 $S$의 크기다.
또한 $D^m$은 여타 튜플 요소에 독립적으로 튜플상의 각 요소를 선택하도록 $D$를 적용하여 유도한 $m$-튜플에 대한 확률이다.

---

$L_(D,f)(h_S)$가 훈련 집합 $S$에 의존하고 $S$가 무작위적인 절차로 선택되었기에 예측기 $h_S$의 선택과 리스크 $L_{(D,f)}(h_S)$에는 무작위성이 존재한다. 
형식적으로는 이를 무작위 변수라고 부른다.
그러나 $S$가 학습자에게 좋은 예측기를 충분히 유도할 수 있다고 말하기는 어렵다. 
표본화된 훈련 데이터가 $D$를 전혀 대변하지 않을 수도 있기 때문이다. 

이처럼 비대변적 표본을 취할 확률을 $\sigma$라고 표기하며 $(1-\sigma)$를 **신뢰 모수**(confidence parameter)라고 부르겠다.
또한 완벽한 라벨 예측을 보장하는 것이 불가능하기에 예측의 질에 대한 또 다른 모수인 **정확도 모수**(accuracy parameter) $\varepsilon$을 도입한다.

학습자의 실패는 $L_{(D,f)}(h_S)>\varepsilon$이다.
$L_{(D,f)}(h_S)\leq\varepsilon$이라면 알고리즘의 출력은 근사적으로 정확한 예측기다. 
따라서 문제는 인스턴스의 $m$-튜플을 표본화하는 확률에 대한 상계다.
이 상계는 학습자의 실패를 유도할 것이다.

형식적으로 $S|_x=(x_1,\ldots,x_m)$이 훈련 집합의 인스턴스라고 하자.
이에 상계를 부여하고 한다.

$$
D^m(\lbrace S|_x:L_{(D,f)}(h_S)>\varepsilon)\rbrace).
$$
