---
title: "파울리 행렬과 내적"
author: 김태원
categories: quantumComputation
tags: [quantumComputation]
---

*Quantum Computation and Quantum Information*

--- 

- **파울리 행렬**(Pauli matrices)은 대단히 유용하다.
- 볼프강 파울리라는 오스트리아 물리학자가 도입한 행렬로, 양자역학에서 스핀 같은
개념을 표현할 때 쓴다.
- $2\times 2$ 복소 행렬로, 아래처럼 표기된다. 

    $$
    \begin{align*}
    \sigma_0 \equiv I &\equiv \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \\
    \sigma_1 \equiv \sigma_x \equiv X &\equiv \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \\
    \sigma_2 \equiv \sigma_y \equiv Y &\equiv \begin{bmatrix} 0 &-i \\ i & 0 \end{bmatrix} \\
    \sigma_3 \equiv \sigma_z \equiv Z &\equiv \begin{bmatrix} 1 & 0 \\ 0 & -i \end{bmatrix}
    \end{align*}
    $$

## 내적

- **내적**(inner product)은 두 벡터 $\ket v$와 $\ket w$를 취해 복소수를 출력으로 내놓는다. 
- $(\cdot,\cdot)$으로 표기하기도 한다.
- $(\cdot,\cdot):V\times V\mapsto\mathbb{C}$는 아래 조건을 만족하면 내적이다.
    1. 선형이다. 즉 $w_i$에 $\lambda$를 취한 다음 내적을 한 결과와 내적을 취한
    다음 $\lambda$를 취한 결과가 일치한다.
    
    $$
    \left(\ket v, \sum_i\lambda_i\ket{w_i}\right) = \sum_i\lambda_i(\ket{v},\ket{w_i})_.
    $$

    2. 교환 법칙이 성립한다. 즉 

    $$
    (\ket{v},\ket{w}) = (\ket{w},\ket{v}).
    $$

    3.  내적의 결과는 $0$보다 크거나 같다. 그리고 내적의 결과가 $0$과 같다는
    것은 한 벡터 $\ket{v}$가 $0$이라는 뜻이다. 즉

    $$
    (\ket{v},\ket{v})\geq 0 \;\&\;(\ket{v},\ket{v})=0\Leftrightarrow\ket v=0.
    $$

- 가령 양자역학에서 중요한 벡터공간인 $\mathbb{C}^n$에서 내적은 아래처럼 정의된다.
    - 여기서 $y^*$는 $y$의 복소켤레(complex conjugate)를 뜻한다. 

    $$
    ((y_1,\ldots,y_n),(z_1,\ldots,z_n)) \equiv
    \sum_i y_i^* z_i= [y_1^*\cdots y_n^*]\begin{bmatrix}z_1\\\vdots\\z_n\end{bmatrix}_.
    $$

- 이때 **힐베르트 공간**이란 유한 차원 복소 벡터공간에 대해 내적이 정의된 공간을 일컫는다. 
- 두 벡터 $\ket{w}$와 $\ket{v}$는 내적이 $0$일 때 **직교**(orthogonal)한다.
    - 예를 들면, 

    $$
    \begin{aligned}
    &\ket{w}\equiv (1,0) \;\&\;\ket{v}\equiv(0,1) \\
    \Rightarrow &(\ket{w},\ket{v})  =0.
    \end{aligned}
    $$

- 벡터 $\ket{v}$의 **노름(norm)** 혹은 크기는 다음처럼 정의한다. 

    $$
    \begin{aligned}
    \|\ket{v}\| &\equiv \sqrt{(\ket{v},\ket{v})}\\ &\equiv\sqrt{\braket{v|v}}_.
    \end{aligned}
    $$

    - **단위 벡터**(unit vector)란 $\|\ket{v}\|=1$인 벡터 $\ket{v}$다.
    - $\|\ket{v}\|=1$이면 $\ket{v}$가 **정규화**(**norm**alized)되었다고 하기도 한다.
        - 벡터를 자신의 노름으로 나누는 것이 정규화다.
    - 벡터 집합상의 각 벡터가 단위 벡터이고 집합상의 벡터가 서로 직교라면 이 벡터집합을 **정규직교**(orthonormal) 집합이라고 한다. 
- 내적이 정의된 벡터공간 $V$에 대해 $\ket{w_1},\ldots,\ket{w_d}$의 기저 집합이 주어질 때, **그람-슈미트** 과정을 통해 정규직교 기저 집합 $\ket{v_1},\ldots,\ket{v_d}$를 만들 수 있다. 

    $$
    \begin{aligned}
    \ket{v_1}&\equiv\frac{w_1}{\|\ket{w_1}\|} \\\\
        (1\leq k &\leq d-1\textrm{에 대해 귀납적으로})\\
    \ket{v_{k+1}}&\equiv\frac{\ket{w_{k+1}}-\sum^k_{i=1}\braket{v_i\ket{w_{k+1}}|v_i}}{\|\ket{w_{k+1}}-\sum^k_{i=1}\braket{v_i\ket{w_{k+1}}|v_i}\|}
    \end{aligned}
    $$

    - bra-ket 표기와 합 표기로 작성해서 이렇게 보일 뿐이지 그냥 기초 선형대수에서 나오는 그 그람-슈미트 과정이다. 
- 이제 선형 연산자에 대한 행렬 표현은 정규직교 입력과 기저 출력을 염두에 둔다. 즉

    $$
    \begin{aligned}
    \ket{w} &= \sum_i w_i\ket{i} \\
    \ket{v} &= \sum_j v_j\ket{j} \\ \Rightarrow
    \braket{i|j} &= \delta_{ij} \\ \Rightarrow 
    \braket{v|w} &= \left(\sum_i v_i\ket i, \sum_j w_j\ket j\right) \\
        &= \sum_{ij}v_i^*w_j\delta_{ij} \\
        &= \sum_i v_i^*w_i \\
        &= [v_1^*,\ldots,v_n^*]\begin{bmatrix}w_1\\\vdots\\ w_n\end{bmatrix}_.
    \end{aligned}
    $$

    - 즉, 두 벡터의 내적은 두 벡터의 행렬 표현 간의 내적과 같은데, 이는 행렬 표현이 동일한 정규직교 기저로 작성되었기 때문이다. 
